{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25cab57d-890a-4da4-b845-8bf21e0884b8",
   "metadata": {},
   "source": [
    "This code is implementing an Artificial Neural Network (ANN) for regression using TensorFlow & Keras. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e85a1b1a-09cc-45b0-9692-d21438194903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6ff8fce-33a0-4473-befb-a75a0c7ba01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('CSV_Data_Sets/all_sites_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b58a0c2a-ed3f-455a-b3c3-ffc88c1d51d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILM</th>\n",
       "      <th>RottenTomatoes</th>\n",
       "      <th>RottenTomatoes_User</th>\n",
       "      <th>Metacritic</th>\n",
       "      <th>Metacritic_User</th>\n",
       "      <th>IMDB</th>\n",
       "      <th>Fandango_Stars</th>\n",
       "      <th>Fandango_Ratingvalue</th>\n",
       "      <th>RT_norm</th>\n",
       "      <th>RT_user_norm</th>\n",
       "      <th>...</th>\n",
       "      <th>IMDB_norm</th>\n",
       "      <th>RT_norm_round</th>\n",
       "      <th>RT_user_norm_round</th>\n",
       "      <th>Metacritic_norm_round</th>\n",
       "      <th>Metacritic_user_norm_round</th>\n",
       "      <th>IMDB_norm_round</th>\n",
       "      <th>Metacritic_user_vote_count</th>\n",
       "      <th>IMDB_user_vote_count</th>\n",
       "      <th>Fandango_votes</th>\n",
       "      <th>Fandango_Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avengers: Age of Ultron (2015)</td>\n",
       "      <td>74</td>\n",
       "      <td>86</td>\n",
       "      <td>66</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.70</td>\n",
       "      <td>4.30</td>\n",
       "      <td>...</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1330</td>\n",
       "      <td>271107</td>\n",
       "      <td>14846</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cinderella (2015)</td>\n",
       "      <td>85</td>\n",
       "      <td>80</td>\n",
       "      <td>67</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.55</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>249</td>\n",
       "      <td>65709</td>\n",
       "      <td>12640</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ant-Man (2015)</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>64</td>\n",
       "      <td>8.1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>...</td>\n",
       "      <td>3.90</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>627</td>\n",
       "      <td>103660</td>\n",
       "      <td>12055</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do You Believe? (2015)</td>\n",
       "      <td>18</td>\n",
       "      <td>84</td>\n",
       "      <td>22</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4.20</td>\n",
       "      <td>...</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>31</td>\n",
       "      <td>3136</td>\n",
       "      <td>1793</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hot Tub Time Machine 2 (2015)</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.40</td>\n",
       "      <td>...</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>88</td>\n",
       "      <td>19560</td>\n",
       "      <td>1021</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Mr. Holmes (2015)</td>\n",
       "      <td>87</td>\n",
       "      <td>78</td>\n",
       "      <td>67</td>\n",
       "      <td>7.9</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>3.90</td>\n",
       "      <td>...</td>\n",
       "      <td>3.70</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>33</td>\n",
       "      <td>7367</td>\n",
       "      <td>1348</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>'71 (2015)</td>\n",
       "      <td>97</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.10</td>\n",
       "      <td>...</td>\n",
       "      <td>3.60</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>60</td>\n",
       "      <td>24116</td>\n",
       "      <td>192</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Two Days, One Night (2014)</td>\n",
       "      <td>97</td>\n",
       "      <td>78</td>\n",
       "      <td>89</td>\n",
       "      <td>8.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.85</td>\n",
       "      <td>3.90</td>\n",
       "      <td>...</td>\n",
       "      <td>3.70</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>123</td>\n",
       "      <td>24345</td>\n",
       "      <td>118</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Gett: The Trial of Viviane Amsalem (2015)</td>\n",
       "      <td>100</td>\n",
       "      <td>81</td>\n",
       "      <td>90</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.05</td>\n",
       "      <td>...</td>\n",
       "      <td>3.90</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1955</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Kumiko, The Treasure Hunter (2015)</td>\n",
       "      <td>87</td>\n",
       "      <td>63</td>\n",
       "      <td>68</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.35</td>\n",
       "      <td>3.15</td>\n",
       "      <td>...</td>\n",
       "      <td>3.35</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>19</td>\n",
       "      <td>5289</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          FILM  RottenTomatoes  \\\n",
       "0               Avengers: Age of Ultron (2015)              74   \n",
       "1                            Cinderella (2015)              85   \n",
       "2                               Ant-Man (2015)              80   \n",
       "3                       Do You Believe? (2015)              18   \n",
       "4                Hot Tub Time Machine 2 (2015)              14   \n",
       "..                                         ...             ...   \n",
       "141                          Mr. Holmes (2015)              87   \n",
       "142                                 '71 (2015)              97   \n",
       "143                 Two Days, One Night (2014)              97   \n",
       "144  Gett: The Trial of Viviane Amsalem (2015)             100   \n",
       "145         Kumiko, The Treasure Hunter (2015)              87   \n",
       "\n",
       "     RottenTomatoes_User  Metacritic  Metacritic_User  IMDB  Fandango_Stars  \\\n",
       "0                     86          66              7.1   7.8             5.0   \n",
       "1                     80          67              7.5   7.1             5.0   \n",
       "2                     90          64              8.1   7.8             5.0   \n",
       "3                     84          22              4.7   5.4             5.0   \n",
       "4                     28          29              3.4   5.1             3.5   \n",
       "..                   ...         ...              ...   ...             ...   \n",
       "141                   78          67              7.9   7.4             4.0   \n",
       "142                   82          83              7.5   7.2             3.5   \n",
       "143                   78          89              8.8   7.4             3.5   \n",
       "144                   81          90              7.3   7.8             3.5   \n",
       "145                   63          68              6.4   6.7             3.5   \n",
       "\n",
       "     Fandango_Ratingvalue  RT_norm  RT_user_norm  ...  IMDB_norm  \\\n",
       "0                     4.5     3.70          4.30  ...       3.90   \n",
       "1                     4.5     4.25          4.00  ...       3.55   \n",
       "2                     4.5     4.00          4.50  ...       3.90   \n",
       "3                     4.5     0.90          4.20  ...       2.70   \n",
       "4                     3.0     0.70          1.40  ...       2.55   \n",
       "..                    ...      ...           ...  ...        ...   \n",
       "141                   4.0     4.35          3.90  ...       3.70   \n",
       "142                   3.5     4.85          4.10  ...       3.60   \n",
       "143                   3.5     4.85          3.90  ...       3.70   \n",
       "144                   3.5     5.00          4.05  ...       3.90   \n",
       "145                   3.5     4.35          3.15  ...       3.35   \n",
       "\n",
       "     RT_norm_round  RT_user_norm_round  Metacritic_norm_round  \\\n",
       "0              3.5                 4.5                    3.5   \n",
       "1              4.5                 4.0                    3.5   \n",
       "2              4.0                 4.5                    3.0   \n",
       "3              1.0                 4.0                    1.0   \n",
       "4              0.5                 1.5                    1.5   \n",
       "..             ...                 ...                    ...   \n",
       "141            4.5                 4.0                    3.5   \n",
       "142            5.0                 4.0                    4.0   \n",
       "143            5.0                 4.0                    4.5   \n",
       "144            5.0                 4.0                    4.5   \n",
       "145            4.5                 3.0                    3.5   \n",
       "\n",
       "     Metacritic_user_norm_round  IMDB_norm_round  Metacritic_user_vote_count  \\\n",
       "0                           3.5              4.0                        1330   \n",
       "1                           4.0              3.5                         249   \n",
       "2                           4.0              4.0                         627   \n",
       "3                           2.5              2.5                          31   \n",
       "4                           1.5              2.5                          88   \n",
       "..                          ...              ...                         ...   \n",
       "141                         4.0              3.5                          33   \n",
       "142                         4.0              3.5                          60   \n",
       "143                         4.5              3.5                         123   \n",
       "144                         3.5              4.0                          19   \n",
       "145                         3.0              3.5                          19   \n",
       "\n",
       "     IMDB_user_vote_count  Fandango_votes  Fandango_Difference  \n",
       "0                  271107           14846                  0.5  \n",
       "1                   65709           12640                  0.5  \n",
       "2                  103660           12055                  0.5  \n",
       "3                    3136            1793                  0.5  \n",
       "4                   19560            1021                  0.5  \n",
       "..                    ...             ...                  ...  \n",
       "141                  7367            1348                  0.0  \n",
       "142                 24116             192                  0.0  \n",
       "143                 24345             118                  0.0  \n",
       "144                  1955              59                  0.0  \n",
       "145                  5289              41                  0.0  \n",
       "\n",
       "[146 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e18d656-251d-430a-a940-4a5092fe79fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.iloc[:,1:-1].values #start from 2 column and convert it to numpy array.\n",
    "y = dataset.iloc[:, -1].values #last column only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1070c95-9d48-4662-a5b9-2e41e6a02839",
   "metadata": {},
   "source": [
    "The function train_test_split() from sklearn.model_selection is used to split a dataset into training and testing sets.\n",
    "This is essential for machine learning to evaluate model performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c3858c6-ae6b-4c21-be30-4cc1d3790aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state = 0) #20% test set 80% training set, random_state = 0: Ensures consistent/random shuffling every time you run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b96f156-a68d-45d0-8a8f-034ecbb3ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential() #Initializes a sequential ANN model, where layers are stacked one after another,  Sets up a blank ANN to which we add layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de063351-eec4-4544-9701-6084f17c61ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units = 6, activation ='relu')) #First hidden layer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de777939-a216-469e-9be0-08d7f82292b6",
   "metadata": {},
   "source": [
    "units=6 → This layer has 6 neurons.\n",
    "activation='relu' → Uses ReLU (Rectified Linear Unit) as the activation function.\n",
    "Why? → ReLU helps the network learn complex patterns while avoiding vanishing gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3944fa1-7cb8-4aec-8b89-dc3502aa6ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units = 6, activation ='relu')) #Second Hidden Layer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8f46c2-9b5f-4235-98ff-c3e27a609be0",
   "metadata": {},
   "source": [
    "1. units=1 → Only 1 neuron in the output layer, as this is a regression problem.\n",
    "2. No activation function because the model should output a continuous numerical value.\n",
    "3. Purpose → Builds a 3-layer ANN (2 hidden layers + 1 output layer) for regression.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc376611-08d6-4a53-90b1-147d12dfc6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units = 1)) #output Layer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8836d1-9d45-41ce-bcb7-e73f44e3d043",
   "metadata": {},
   "source": [
    "1. optimizer='adam' → Uses Adam optimizer, an advanced gradient descent algorithm.\n",
    "2. loss='mean_squared_error' → Uses MSE (Mean Squared Error) as the loss function (good for regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "898776ce-dacd-463b-807b-0703001e8029",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06ade11-f302-4536-a82e-42a6ebb4610d",
   "metadata": {},
   "source": [
    "1. x_train, y_train → The training data.\n",
    "2. batch_size=32 → Trains the model in batches of 32 samples at a time (improves efficiency).\n",
    "3. epochs=100 → Runs 100 iterations over the training data.\n",
    "4. Purpose → Trains the neural network to adjust weights & biases for best predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ba7898c-bbc4-4fee-84bc-3dd0c2b42c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 86.6192 \n",
      "Epoch 2/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 87.1459 \n",
      "Epoch 3/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 71.0349\n",
      "Epoch 4/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 83.6007 \n",
      "Epoch 5/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 69.8325 \n",
      "Epoch 6/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 85.5173 \n",
      "Epoch 7/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 69.0735\n",
      "Epoch 8/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 66.4377\n",
      "Epoch 9/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 83.5109\n",
      "Epoch 10/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 67.6390\n",
      "Epoch 11/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 82.0977\n",
      "Epoch 12/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 67.1915\n",
      "Epoch 13/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 66.4768\n",
      "Epoch 14/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 66.4635 \n",
      "Epoch 15/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 77.0933\n",
      "Epoch 16/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 79.5720\n",
      "Epoch 17/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 81.2265 \n",
      "Epoch 18/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 67.2074 \n",
      "Epoch 19/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 78.7970\n",
      "Epoch 20/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 62.4192\n",
      "Epoch 21/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 62.8671 \n",
      "Epoch 22/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 77.4668\n",
      "Epoch 23/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 75.1887\n",
      "Epoch 24/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 75.2538 \n",
      "Epoch 25/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 76.7249\n",
      "Epoch 26/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 75.7999\n",
      "Epoch 27/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 63.6597\n",
      "Epoch 28/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 63.3313\n",
      "Epoch 29/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 62.0225\n",
      "Epoch 30/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 75.9382\n",
      "Epoch 31/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 59.9066\n",
      "Epoch 32/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 74.2971\n",
      "Epoch 33/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 77.6532\n",
      "Epoch 34/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 73.5507 \n",
      "Epoch 35/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 63.8653\n",
      "Epoch 36/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 74.7448\n",
      "Epoch 37/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 61.8706 \n",
      "Epoch 38/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 61.3154\n",
      "Epoch 39/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 58.8924\n",
      "Epoch 40/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 73.9015\n",
      "Epoch 41/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 75.1151\n",
      "Epoch 42/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 74.1978\n",
      "Epoch 43/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 58.9839\n",
      "Epoch 44/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 71.0162\n",
      "Epoch 45/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 62.7526\n",
      "Epoch 46/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 60.6688\n",
      "Epoch 47/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 69.8388\n",
      "Epoch 48/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 57.3267 \n",
      "Epoch 49/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 57.0069\n",
      "Epoch 50/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 59.8303\n",
      "Epoch 51/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 58.4040\n",
      "Epoch 52/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 73.1582\n",
      "Epoch 53/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 71.3630\n",
      "Epoch 54/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 58.8116\n",
      "Epoch 55/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 67.9488\n",
      "Epoch 56/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 57.2762\n",
      "Epoch 57/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 59.3665\n",
      "Epoch 58/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 70.1974\n",
      "Epoch 59/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 58.0738\n",
      "Epoch 60/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 70.8112\n",
      "Epoch 61/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 57.7370\n",
      "Epoch 62/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 68.0297\n",
      "Epoch 63/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 68.7098 \n",
      "Epoch 64/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 68.6250\n",
      "Epoch 65/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 60.6601\n",
      "Epoch 66/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 71.1191\n",
      "Epoch 67/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 67.2176 \n",
      "Epoch 68/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 58.4388 \n",
      "Epoch 69/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 67.6066\n",
      "Epoch 70/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 54.9345 \n",
      "Epoch 71/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 55.0977\n",
      "Epoch 72/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 64.2085 \n",
      "Epoch 73/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 68.5308 \n",
      "Epoch 74/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 70.2439\n",
      "Epoch 75/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 68.3288 \n",
      "Epoch 76/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 56.9667 \n",
      "Epoch 77/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 52.7936\n",
      "Epoch 78/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 55.9777 \n",
      "Epoch 79/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 51.7923 \n",
      "Epoch 80/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 53.4285 \n",
      "Epoch 81/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 57.3132\n",
      "Epoch 82/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 67.8254 \n",
      "Epoch 83/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 56.6314\n",
      "Epoch 84/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 53.5667 \n",
      "Epoch 85/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 64.1489\n",
      "Epoch 86/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 53.0824\n",
      "Epoch 87/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 65.1706\n",
      "Epoch 88/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 66.7334 \n",
      "Epoch 89/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 62.9822\n",
      "Epoch 90/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 54.4842\n",
      "Epoch 91/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 55.4291\n",
      "Epoch 92/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 64.9689\n",
      "Epoch 93/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 52.9310\n",
      "Epoch 94/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 66.0879\n",
      "Epoch 95/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 51.4919\n",
      "Epoch 96/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 69.0477\n",
      "Epoch 97/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 56.0341 \n",
      "Epoch 98/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 65.3135\n",
      "Epoch 99/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 64.2030 \n",
      "Epoch 100/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 55.1292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x15f16f8c0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(x_train,y_train, batch_size = 64, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d75b6a4-8e1b-4dc9-8c9e-65ceef9812a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "[[  6.7    0.5 ]\n",
      " [  5.13   0.4 ]\n",
      " [  8.17   0.4 ]\n",
      " [ 10.34   0.1 ]\n",
      " [  9.9    0.  ]\n",
      " [  1.34   0.3 ]\n",
      " [  9.73   0.4 ]\n",
      " [  1.67   0.4 ]\n",
      " [ -3.96   0.1 ]\n",
      " [  0.67   0.4 ]\n",
      " [  7.86   0.4 ]\n",
      " [ -6.88   0.2 ]\n",
      " [-15.28   0.  ]\n",
      " [  5.26   0.3 ]\n",
      " [  6.4    0.3 ]\n",
      " [  7.     0.2 ]\n",
      " [  2.28   0.4 ]\n",
      " [  6.55   0.3 ]\n",
      " [  2.63   0.1 ]\n",
      " [  7.8    0.5 ]\n",
      " [  3.73   0.2 ]\n",
      " [  7.13   0.4 ]\n",
      " [  8.79   0.1 ]\n",
      " [  1.12   0.2 ]\n",
      " [  9.93   0.  ]\n",
      " [  1.57   0.4 ]\n",
      " [  8.36   0.  ]\n",
      " [  2.01   0.2 ]\n",
      " [ -0.53   0.2 ]\n",
      " [ -0.47   0.1 ]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(x_test)\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1) , y_test.reshape(len(y_test),1)), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357c6397-4a26-4cc2-81b2-f6206d0b361c",
   "metadata": {},
   "source": [
    "1. np.set_printoptions(precision=2) → Limits printed numbers to 2 decimal places.\n",
    "2. y_pred.reshape(len(y_pred), 1) → Reshapes predictions into a column vector.\n",
    "3. y_test.reshape(len(y_test), 1) → Reshapes actual values into a column vector.\n",
    "4. np.concatenate(..., 1) → Combines predicted & actual values side by side.\n",
    "5. Purpose → Neatly displays predictions vs actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ff75e4-e259-4566-b4f8-61ae0ab13bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
